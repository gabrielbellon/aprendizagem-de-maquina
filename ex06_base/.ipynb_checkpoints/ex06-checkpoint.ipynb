{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"figs/LogoUFSCar.jpg\" alt=\"Logo UFScar\" width=\"110\" align=\"left\"/>  <br/> <center>Universidade Federal de São Carlos (UFSCar)<br/><font size=\"4\"> Departamento de Computação, campus Sorocaba</center></font>\n",
    "</p>\n",
    "\n",
    "<br/>\n",
    "<font size=\"4\"><center><b>Disciplina: Aprendizado de Máquina</b></center></font>\n",
    "  \n",
    "<font size=\"3\"><center>Prof. Dr. Tiago A. Almeida</center></font>\n",
    "\n",
    "<br/>\n",
    "<center><i><b>\n",
    "Atenção: não são autorizadas cópias, divulgações ou qualquer tipo de uso deste material sem o consentimento prévio dos autores.\n",
    "</center></i></b>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Exercício - Protocolo Experimental e Análise</center>\n",
    "\n",
    "Instruções\n",
    "----------\n",
    "\n",
    "Este arquivo contém o código que auxiliará no desenvolvimento do exercício. Você precisará completar as seguintes funções:\n",
    "\n",
    "* `stratified_holdOut()`\n",
    "* `get_confusionMatrix()`\n",
    "* `relatorioDesempenho()`\n",
    "* `curva_aprendizado()`\n",
    "* `gridSearch()`\n",
    "* `stratified_kfolds()`\n",
    "\n",
    "Você não poderá criar nenhuma outra função. Apenas altere as rotinas fornecidas.\n",
    "\n",
    "Introdução\n",
    "----------\n",
    "\n",
    "Este exercício abordará metodologia experimental e análise de desempenho. Para isso, empregaremos uma regressão logística para comparar o desempenho usando holdout (treino, validação e teste) e validação cruzada *k*-fold, com medidas de acurácia, precisão, revocação e F-medida. Adicionalmente, iremos implementar busca em grade para encontrar o melhor parâmetro de regularização da regressão logística. Por fim, vamos plotar curvas de aprendizado para avaliar se o método está sofrendo de over/under fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Holdout\n",
    "\n",
    "Inicialmente, vamos implementar a validação holdout estratificada.\n",
    "\n",
    "Primeiro, vamos carregar a base de dados e visualizar as primeiras amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Caminho dos arquivos\n",
    "FILES_DIRECTORY = \"dados\"\n",
    "\n",
    "import numpy as np # importa a biblioteca usada para trabalhar com vetores e matrizes\n",
    "import pandas as pd # importa a biblioteca usada para trabalhar com dataframes e análise de dados\n",
    "import os # importa a biblioteca para tarefas relacionadas ao sistema operacional\n",
    "\n",
    "# Função para plotar os dados\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importa o arquivo e guarda em um dataframe do Pandas\n",
    "df_dataset = pd.read_csv( os.path.join(FILES_DIRECTORY, 'data.csv'), sep=',', index_col=None)\n",
    "\n",
    "# Pega os valores das n-1 primeiras colunas e guarda em uma matrix X\n",
    "X = df_dataset.iloc[:, 0:-1].values \n",
    "\n",
    "# Pega os valores da última coluna e guarda em um vetor Y\n",
    "Y = df_dataset.iloc[:, -1].values \n",
    "\n",
    "# Imprime as 5 primeiras linhas da matriz X\n",
    "display('X:', X[0:5,:])\n",
    "\n",
    "# Imprime os 5 primeiros valores de Y\n",
    "print('Y:', Y[0:5])\n",
    "\n",
    "# obtem e imprimi as classes do problema\n",
    "classes = np.unique(Y)\n",
    "print('\\nClasses: ', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos plotar as amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizarDados(X,Y):\n",
    "    \"\"\"\n",
    "    Função usada para plotar os dados\n",
    "    \"\"\"\n",
    "    \n",
    "    # definindo o tamanho da figura \n",
    "    plt.figure(figsize=(10,8))\n",
    "    \n",
    "    # plota os dados da classe 0\n",
    "    plt.scatter( X[Y==0,0], X[Y==0,1], label='Classe 0', color='blue', s=50, edgecolors='k') \n",
    "    \n",
    "    # plota os dados da classe 1\n",
    "    plt.scatter( X[Y==1,0], X[Y==1,1], label='Classe 1', color='red', s=50, edgecolors='k') \n",
    "        \n",
    "    # Plota a legenda\n",
    "    plt.legend()\n",
    "\n",
    "# Efetua o plot\n",
    "visualizarDados(X,Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A validação holdout estratificada consiste em dividir a base de dados em duas partições (treino e teste), mantendo a distribuição original de dados de cada classe em cada partição. \n",
    "\n",
    "É importante que as partições de treinamento e teste sejam geradas de forma aleatória. Portanto, no script abaixo, antes de chamarmos a função que gera os conjuntos de treinamento e teste, iremos embaralhar os dados. Para que toda a execução gere o mesmo resultado, vamos usar uma semente para a função de geração de números aleatórios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semente usada na randomizacao dos dados.\n",
    "randomSeed = 10 \n",
    "\n",
    "# gera os indices aleatorios que irao definir a ordem dos dados\n",
    "idx_perm = np.random.RandomState(randomSeed).permutation(range(len(Y)))\n",
    "\n",
    "# ordena os dados de acordo com os indices gerados aleatoriamente\n",
    "X2, Y2 = X[idx_perm, :], Y[idx_perm]\n",
    "\n",
    "print('Dados embaralhados com sucesso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você precisará completar a função `stratified_holdOut()`. A função que você irá implementar deverá retornar os índices dos dados de treinamento e os índices dos dados de teste. Os primeiros $p\\%$ dos dados de cada classe devem compor o conjunto de treinamento, enquanto o restante deve compor os dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_holdOut(target, pTrain):\n",
    "    \"\"\"\n",
    "    Retorna os indices dos dados de treinamento e teste \n",
    "    \n",
    "    Parâmetros\n",
    "    ----------   \n",
    "    target: vetor com as classes dos dados\n",
    "    \n",
    "    pTrain: porcentagem de dados de treinamento\n",
    "    \n",
    "    Retorno\n",
    "    -------\n",
    "    train_index: índices dos dados de treinamento \n",
    "    test_index: índices dos dados de teste \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # inicializa as variaveis que precisam ser retornadas \n",
    "    train_index = []\n",
    "    test_index = []\n",
    "\n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ###############################\n",
    "    #  Instruções: Complete o codigo para retornar os índices dos dados de  \n",
    "    #              treinamento e dos dados de teste.\n",
    "    #              \n",
    "    #              Obs: - os conjuntos de treinamento e teste devem ser criados\n",
    "    #                     de maneira estratificada, ou seja, deve ser mantida a \n",
    "    #                     a distribuição original dos dados de cada classe em cada \n",
    "    #                     conjunto. Em outras palavras, o conjunto de treinamento deve ser\n",
    "    #                     formado por pTrain% dos dados da primeira classe, pTrain% dos dados da \n",
    "    #                     segunda classe e assim por diante. \n",
    "    #\n",
    "    #                   - a porcentagem de dados de teste para cada classe é igual a \n",
    "    #                     1-pTrain (parametro da funcao que contem a porcentagem de dados \n",
    "    #                     de treinamento)\n",
    "    #\n",
    "    #                   - dentro de uma determinada particao, mantenha a ordem dos dados igual\n",
    "    #                      a ordem original do vetor target. Exemplo: se as amostras com os índices 1, 3 e 6 foram \n",
    "    #                      escolhidas para fazerem parte do conjunto de teste, garanta que no conjunto de \n",
    "    #                      teste, elas permanecam na mesma ordem: a amostra de índice 1 fique antes da amostra de índice 3\n",
    "    #                      e esta fique antes da amostra de indice 6. \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ##################################################################################\n",
    "    \n",
    "    return train_index, test_index\n",
    "\n",
    "# define a porcentagem de dados que irao compor o conjunto de treinamento\n",
    "pTrain = 0.8 \n",
    "\n",
    "# obtem os indices dos dados da particao de treinamento e da particao de teste\n",
    "train_index, test_index = stratified_holdOut(Y2, pTrain)\n",
    "\n",
    "print('Indices dos cinco primeiros dados de treinamento: \\n',train_index[0:5])\n",
    "\n",
    "print('Indices dos cinco primeiros dados de teste: \\n',test_index[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo serão exibidas algumas informações sobre as partições de treinamento e de teste retornadas pela função `stratified_holdOut()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gera as matrizes com os dados de treinamento e teste e os vetores \n",
    "# das classes a partir dos indices retornado pela funcao stratified_holdOut() \n",
    "X_train, X_test = X2[train_index, :], X2[test_index, :]\n",
    "Y_train, Y_test = Y2[train_index], Y2[test_index]\n",
    "\n",
    "print('Qtd. dados de treinamento: %d (%1.2f%%)' %(X_train.shape[0], (X_train.shape[0]/X.shape[0])*100) )\n",
    "print('Qtd. de dados de teste: %d (%1.2f%%)' %(X_test.shape[0], (X_test.shape[0]/X.shape[0])*100) )\n",
    "\n",
    "# imprime a porcentagem de dados de treinamento de cada classe\n",
    "print(\"\\nQtd. de dados de cada classe (treinamento)\")\n",
    "cTrain, counts_cTrain = np.unique(np.sort(Y_train), return_counts=True)\n",
    "for i in range( len(cTrain) ):\n",
    "    print('\\tClasse %s: %d (%1.2f%%)' %( cTrain[i],counts_cTrain[i],(counts_cTrain[i]/len(Y_train))*100 ) )\n",
    "\n",
    "# imprime a porcetagem de dados de teste de cada classe\n",
    "print(\"\\nQtd. de dados de cada classe (teste)\")\n",
    "cTest, counts_cTest = np.unique(np.sort(Y_test), return_counts=True)\n",
    "for i in range( len(cTrain) ):\n",
    "    print('\\tClasse %s: %d (%1.2f%%)' %( cTest[i],counts_cTest[i],(counts_cTest[i]/len(Y_test))*100 ) )\n",
    "\n",
    "# imprime os indices dos 10 primeiros dados de treinamento \n",
    "print(\"\\nClasses dos 20 primeiros dados de treinamento\")\n",
    "print(Y_train[0:20])\n",
    "\n",
    "# imprime os indices dos 10 primeiros dados de teste \n",
    "print(\"\\nClasses dos 20 primeiros dados de teste\")\n",
    "print(Y_test[0:20])\n",
    "\n",
    "print('\\n\\n'+\"-\"*80+'\\nSe sua implementacao estiver correta: ')\n",
    "print('\\t- O conjunto de treinamento deve conter 688 dados (80.00%)')\n",
    "print('\\t- O conjunto de teste deve conter 172 dados (20.00%)')\n",
    "\n",
    "print('\\nSe sua implementacao estiver correta, o conjunto de treinamento deve conter: ')\n",
    "print('\\t- 304 dados da classe 0 (44.19%)')\n",
    "print('\\t- 384 dados da classe 1 (55.81%)')\n",
    "\n",
    "print('\\nSe sua implementacao estiver correta, o conjunto de teste deve conter: ')\n",
    "print('\\t- 76 dados da classe 0 (44.19%)')\n",
    "print('\\t- 96 dados da classe 1 (55.81%)')\n",
    "\n",
    "print('\\nSe sua implementacao estiver correta, as classes dos 20 primeiros dados de treinamento devem ser: ')\n",
    "print('[1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1]')\n",
    "\n",
    "print('\\nSe sua implementacao estiver correta, as classes dos 20 primeiros dados de teste devem ser: ')\n",
    "print('[1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que separamos os dados em duas partições, podemos treinar um método de classicação na partição de treinamento e testar na partição de teste. Para isso, vamos usar a Regressão Logística, cujo código está na pasta raíz desse exercício. Como os dados não são linearmente separáveis, no script abaixo, antes de treinar a Regressão Logística, são adicionados atributos polinomiais nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa as funções da regressao logística\n",
    "from logisticRegression import atributosPolinomiais, predicao, treinamento\n",
    "\n",
    "# adiciona novas colunas que correspondem a atributos polinomiais\n",
    "Xpol_train = atributosPolinomiais(X_train[:,0],X_train[:,1]) \n",
    "print('Dimensão do novo conjunto de dados polinomiais (treino): \\n', Xpol_train.shape)\n",
    "\n",
    "Xpol_test = atributosPolinomiais(X_test[:,0],X_test[:,1]) \n",
    "print('\\nDimensão do novo conjunto de dados polinomiais (teste): \\n', Xpol_test.shape)\n",
    "\n",
    "# Configura o parametro regularizacao lambda igual a 1\n",
    "lambda_reg = 1\n",
    "\n",
    "# Configura o numero de interacaoes da regressao\n",
    "iteracoes = 1000\n",
    "\n",
    "# executa o treinamento e obtém os valores de theta usando regressão logística (arquivo logisticRegression.py)\n",
    "theta = treinamento(Xpol_train, Y_train, lambda_reg, iteracoes)\n",
    "\n",
    "# classifica os dados de teste\n",
    "Y_pred = predicao(Xpol_test, theta)\n",
    "\n",
    "print('\\nPredição obtida para as 20 primeiras amostras de teste:\\n', Y_pred[0:20])\n",
    "\n",
    "print('\\n\\nSe sua implementacao estiver correta, as predicoes obtidas para as 20 primeiras amostras de teste foram:')\n",
    "print(' [1 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 0]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusão\n",
    "\n",
    "Agora que treinamos o método de classificação, precisamos avaliar o seu desempenho. A maioria das medidas de desempenho pode ser calculada a partir da matriz de confusão. A Tabela 1 apresenta um exemplo de matriz de confusão para um problema com duas classes: **pos** e **neg**. \n",
    "\n",
    " <table style=\"text-align:center\">\n",
    "  <tr>\n",
    "    <th> </th>\n",
    "    <th>Predição = pos</th>\n",
    "    <th>Predição = neg</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Classe = pos</b></td>\n",
    "    <td>vp</td>\n",
    "    <td>fn</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td><b>Classe = neg</b></td>\n",
    "    <td>fp</td>\n",
    "    <td>vn</td>\n",
    "  </tr>\n",
    "</table> \n",
    "<br/>\n",
    "<center><em>Tabela 1. Exemplo de matriz de confusão para um problema binário.</em></center>\n",
    "\n",
    "A partir da matriz de confusão mostrada acima, podemos coletar os seguintes valores:\n",
    "\n",
    "* **verdadeiros positivos (vp)**: quantidade de exemplos corretamente classificados como pertencentes à classe positiva.\n",
    "* **falsos positivos (fp)**: quantidade de exemplos incorretamente classificados como pertencentes à classe positiva.\n",
    "* **verdadeiros negativos (vn)**: quantidade de exemplos corretamente classificados como pertencentes à classe negativa.\n",
    "* **falsos negativos (fn)**: quantidade de exemplos incorretamente classificados como pertencentes à classe negativa.\n",
    "\n",
    "A matriz de confusão apresentada na Tabela 1 pode ser facilmente estendida para problemas multiclasse. Para um problema de $|C|$ classes, a matriz de confusão terá dimensão $|C|x|C|$ e pode ser representada conforme mostra a Tabela 2.\n",
    "\n",
    " <table>\n",
    "  <tr style=\"text-align:center\">\n",
    "    <th> </th>\n",
    "    <th style=\"text-align:center\">Predição = $c_1$</th>\n",
    "    <th style=\"text-align:center\">Predição = $c_2$</th>\n",
    "    <th style=\"text-align:center\">$\\dots$</th>\n",
    "    <th style=\"text-align:center\">Predição = $c_{|C|}$</th>\n",
    "  </tr>\n",
    "  <tr style=\"text-align:center\">\n",
    "    <td style=\"text-align:center\"><b>Classe = $c_1$</b></td>\n",
    "    <td style=\"text-align:center\">$k_{11}$</td>\n",
    "    <td style=\"text-align:center\">$k_{12}$</td>\n",
    "    <td style=\"text-align:center\">$\\dots$</td>\n",
    "    <td style=\"text-align:center\">$k_{1|C|}$</td>\n",
    "  </tr>\n",
    "  <tr style=\"text-align:center\">\n",
    "    <td style=\"text-align:center\"><b>Classe = $c_2$</b></td>\n",
    "    <td style=\"text-align:center\">$k_{21}$</td>\n",
    "    <td style=\"text-align:center\">$k_{22}$</td>\n",
    "    <td style=\"text-align:center\">$\\dots$</td>\n",
    "    <td style=\"text-align:center\">$k_{2|C|}$</td>\n",
    "  </tr>\n",
    "  <tr style=\"text-align:center\">\n",
    "    <td style=\"text-align:center\"><b>$\\vdots$</b></td>\n",
    "    <td style=\"text-align:center\">$\\vdots$</td>\n",
    "    <td style=\"text-align:center\">$\\vdots$</td>\n",
    "    <td style=\"text-align:center\">$\\ddots$</td>\n",
    "    <td style=\"text-align:center\">$\\vdots$</td>\n",
    "  </tr>\n",
    "  <tr style=\"text-align:center\">\n",
    "    <td style=\"text-align:center\"><b>Classe = $c_n$</b></td>\n",
    "    <td style=\"text-align:center\">$k_{|C|1}$</td>\n",
    "    <td style=\"text-align:center\">$k_{|C|2}$</td>\n",
    "    <th style=\"text-align:center\">$\\dots$</th>\n",
    "    <td style=\"text-align:center\">$k_{|C||C|}$</td>\n",
    "  </tr>\n",
    "</table> \n",
    "<br/>\n",
    "<center><em>Tabela 2. Exemplo de matriz de confusão para um problema multiclasse.</em></center>\n",
    "\n",
    "A quantidade de **vp**, **vn**, **fp** e **fn** em relação a uma classe $c_j$, usando-se os valores apresentados na matriz de confusão (Tabela 2), pode ser calculada da seguinte forma:\n",
    "\n",
    "* $\\text{vp}_j=k_{jj}$: quantidade de exemplos corretamente classificados como pertencentes à classe $c_j$;\n",
    "\n",
    "* $\\text{fp}_j=\\sum_{p=1|p\\neq j}^{{|\\mathcal{C}|}} k_{pj}$: quantidade de exemplos incorretamente classificados como pertencentes à classe $c_j$; \n",
    " \n",
    "* $\\text{vn}_j=\\sum_{i=1|i\\neq j}^{{|\\mathcal{C}|}} \\sum_{p=1|p\\neq j}^{{|\\mathcal{C}|}} k_{pi}$: quantidade de exemplos corretamente classificados como não pertencentes à classe $c_j$; \n",
    "\n",
    "* $\\text{fn}_j=\\sum_{p=1|p\\neq j}^{{|\\mathcal{C}|}} k_{jp}$: quantidade de exemplos da classe $c_j$ incorretamente classificados como pertencentes a outra classe. \n",
    "\n",
    "Outra maneira de calcular **vp**, **vn**, **fp** e **fn** para uma classe $c_j$ em um problema multiclasse é gerar uma matriz de confusão binária onde $c_j$ é considerada a classe positiva e todas as outras são consideradas uma única classe negativa.\n",
    "\n",
    "Agora, você precisa gerar a matriz de confusão a partir dos resultados obtidos. A matriz de confusão precisa ter dimensão $|C|x|C|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_confusionMatrix(Y_test, Y_pred, classes):\n",
    "    \"\"\"\n",
    "    Retorna a matriz de confusao, onde o numero de linhas e \n",
    "        e numero de colunas e igual ao numero de classes\n",
    "        \n",
    "    Parametros\n",
    "    ----------   \n",
    "    Y_test: vetor com as classes verdadeiras dos dados\n",
    "    \n",
    "    Y_pred: vetor com as classes preditas pelo metodo de classificacao\n",
    "    \n",
    "    classes: classes do problema\n",
    "    \n",
    "    \n",
    "    Retorno\n",
    "    -------\n",
    "    cm: matriz de confusao (array numpy, em que o numero de linhas e de colunas\n",
    "        e igual ao numero de classes)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # inicia a matriz de confusão\n",
    "    cm = np.zeros( [len(classes),len(classes)], dtype=int )\n",
    "\n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ###############################\n",
    "    #  Instruções: Complete o codigo para retornar a matriz de confusao baseada nas\n",
    "    #           classes verdadeiras dos dados versus as classes preditas pelo metodo\n",
    "    #           de classificacao. \n",
    "    #\n",
    "    #           Obs: cuidado com a ordem das classes na geracao da matriz de confusao.  \n",
    "    #                Os valores da i_esima linha da matriz de confusao devem ser calculados\n",
    "    #                com base na i-esima classe do vetor \"classes\" que é passado como \n",
    "    #                parametro da funcao. Os valores da j-esima coluna da matriz de confusao \n",
    "    #                devem ser calculados com base na j-esima classe do vetor \"classes\".                 \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ##################################################################################\n",
    "    \n",
    "    return cm\n",
    " \n",
    "# Compute confusion matrix\n",
    "cm = get_confusionMatrix(Y_test, Y_pred, classes)\n",
    "\n",
    "print('Matriz de confusão: ')\n",
    "display(cm)\n",
    "\n",
    "print('Se sua implementacao estiver correta, a matriz de confusao gerada sera:')\n",
    "print('[[55, 21]',)\n",
    "print(' [19, 77]]',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medidas de desempenho\n",
    "\n",
    "Agora que obtivemos a matriz de confusão, vamos usá-la como base para calcular o desempenho do algoritmo de classificação. Algumas medidas de desempenho (*e.g.*, acurácia) retornam um valor global de desempenho, enquanto que outras medidas (*e.g.*, precisão, revocação e F-medida) retornam um valor que pode variar dependendo de qual classe é considerada como positiva (classe alvo do problema). Supondo que em um determinado problema, a classe $c_1$ seja considerada a classe positiva, as seguintes medidas de desempenho podem ser calculadas:\n",
    "\n",
    "* $\\displaystyle \\text{acurácia} =\\frac{vp_1+vn_1}{vp_1+vn_1+fp_1+fn_1} = \\frac{\\text{Qtd. de predições corretas}}{\\text{Qtd. de amostras}};$\n",
    "\n",
    "* $\\displaystyle \\text{revocação} =  \\frac{vp_1}{vp_1+fn_1} \\text{;} $\n",
    "\n",
    "* $\\displaystyle \\text{precisão} = \\frac{vp_1}{vp_1+fp_1}; $\n",
    "\n",
    "* $\\displaystyle \\text{F-medida} = 2 \\times \\frac{\\text{precisão} \\times\\text{sensitividade}}{\\text{precisão}+\\text{sensitividade}}.$\n",
    "\n",
    "Para problemas binários sem uma classe-alvo ou para problemas multiclasse, normalmente são utilizadas medidas de desempenho que consideram a média entre os resultados relativos a cada classe do problema. As duas principais estratégias para obter a média de desempenho entre as classes são a média macro e a média micro. A média macro considera que todas as classes possuem a mesma importância. Por outro lado, na média micro, o resultado final é dominado pelas classes mais frequentes, o que pode gerar um desempenho superestimado quando as classes são muito desbalanceadas. Abaixo, são apresentadas algumas medidas de desempenho calculadas por meio dessas duas estratégias.\n",
    "\n",
    "* Medidas baseadas na média macro:\n",
    " - $ \\displaystyle \\text{macro revocação} = \\frac{1}{{|\\mathcal{C}|}} \\times \\sum_{j=1}^{{|\\mathcal{C}|}} \\frac{vp_j}{vp_j+fn_j}$;\n",
    "\t\t\n",
    " - $ \\displaystyle \\text{macro precisão} = \\frac{1}{{|\\mathcal{C}|}} \\times \\sum_{j=1}^{{|\\mathcal{C}|}} \\frac{vp_j}{vp_j+fp_j}$;\n",
    "\t\t\n",
    " - $ \\displaystyle \\text{macro F-medida} = 2 \\times \\frac{\\text{macro precisão} \\times\\text{macro revocação}}{\\text{macro precisão}+\\text{macro revocação}}$.\n",
    "\n",
    "\n",
    "* Medidas baseadas na média micro:\n",
    " - $ \\displaystyle \\text{micro revocação} = \\frac{\\sum_{j=1}^{{|\\mathcal{C}|}} vp_j}{\\sum_{j=1}^{{|\\mathcal{C}|}} vp_j+fn_j}$;\n",
    "\n",
    " - $ \\displaystyle \\text{micro precisão} = \\frac{\\sum_{j=1}^{{|\\mathcal{C}|}} vp_j}{\\sum_{j=1}^{{|\\mathcal{C}|}} vp_j+fp_j}$; \n",
    "\n",
    " - $ \\displaystyle \\text{micro F-medida} = 2 \\times \\frac{\\text{micro precisão} \\times\\text{micro revocação}}{\\text{micro precisão}+\\text{micro revocação}}$.\n",
    "\n",
    "Agora, você deve calcular a **precisão**, **revocação** e **F-medida** para cada uma das classes do problema. Adicionalmente, você deve calcular a **acurácia**, **macro** e **micro precisão**, **macro** e **micro revocação** e, por fim, a **macro** e **micro F-medida**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relatorioDesempenho(matriz_confusao, classes, imprimeRelatorio=False):\n",
    "    \"\"\"\n",
    "    Funcao usada calcular as medidas de desempenho da classificação.\n",
    "\n",
    "    Parametros\n",
    "    ----------   \n",
    "    matriz_confusao: array numpy que representa a matriz de confusao \n",
    "                   obtida na classificacao. O numero de linhas e de colunas\n",
    "                   dessa matriz e igual ao numero de classes.\n",
    "\n",
    "    classes: classes do problema\n",
    "\n",
    "    imprimeRelatorio: variavel booleana que indica se o relatorio de desempenho\n",
    "                    deve ser impresso ou nao. \n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    resultados: variavel do tipo dicionario (dictionary). As chaves\n",
    "              desse dicionario serao os nomes das medidas de desempenho; os valores\n",
    "              para cada chave serao as medidas de desempenho calculadas na funcao.\n",
    "\n",
    "              Mais especificamente, o dicionario devera conter as seguintes chaves:\n",
    "\n",
    "               - acuracia: valor entre 0 e 1 \n",
    "               - revocacao: um vetor contendo a revocacao obtida em relacao a cada classe\n",
    "                            do problema\n",
    "               - precisao: um vetor contendo a precisao obtida em relacao a cada classe\n",
    "                            do problema\n",
    "               - fmedida: um vetor contendo a F-medida obtida em relacao a cada classe\n",
    "                            do problema\n",
    "               - revocacao_macroAverage: valor entre 0 e 1\n",
    "               - precisao_macroAverage: valor entre 0 e 1\n",
    "               - fmedida_macroAverage: valor entre 0 e 1\n",
    "               - revocacao_microAverage: valor entre 0 e 1\n",
    "               - precisao_microAverage: valor entre 0 e 1\n",
    "               - fmedida_microAverage: valor entre 0 e 1\n",
    "    \"\"\"\n",
    "\n",
    "    n_teste = sum(sum(matriz_confusao))\n",
    "\n",
    "    nClasses = len( matriz_confusao ) #numero de classes\n",
    "\n",
    "    # inicializa as medidas que deverao ser calculadas\n",
    "    vp=np.zeros( nClasses ) # quantidade de verdadeiros positivos\n",
    "    vn=np.zeros( nClasses ) # quantidade de verdadeiros negativos\n",
    "    fp=np.zeros( nClasses ) # quantidade de falsos positivos\n",
    "    fn=np.zeros( nClasses ) # quantidade de falsos negativos\n",
    "\n",
    "    acuracia = 0.0 \n",
    "\n",
    "    revocacao = np.zeros( nClasses ) # nesse vetor, devera ser guardada a revocacao para cada uma das classes\n",
    "    revocacao_macroAverage = 0.0\n",
    "    revocacao_microAverage = 0.0\n",
    "\n",
    "    precisao = np.zeros( nClasses ) # nesse vetor, devera ser guardada a revocacao para cada uma das classes\n",
    "    precisao_macroAverage = 0.0\n",
    "    precisao_microAverage = 0.0\n",
    "\n",
    "    fmedida = np.zeros( nClasses ) # nesse vetor, devera ser guardada a revocacao para cada uma das classes\n",
    "    fmedida_macroAverage = 0.0\n",
    "    fmedida_microAverage = 0.0\n",
    "\n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ###############################\n",
    "    #  Instrucoes: Complete o codigo para calcular as seguintes medidas \n",
    "    #              de desempenho: acuracia, revocacao, precisao e F-medida.\n",
    "    #              Para as medidas revocacao, precisao e F-medida, voce\n",
    "    #              devera obter o valor correspondente a cada uma das classes.\n",
    "    #              Voce também precisara calcular as medias macro e micro das \n",
    "    #              medidas revocacao, precisao e F-medida.\n",
    "    #              \n",
    "    #              Obs: voce deve calcular a quantidade de verdadeiros/falsos positivos e  \n",
    "    #              verdadeiros/falsos negativos em relacao a cada classe e usar esses \n",
    "    #              valores para calcular todas as medidas de desempenho. \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ##################################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # imprimindo os resultados para cada classe\n",
    "    if imprimeRelatorio:\n",
    "        \n",
    "        print('\\n\\tRevocacao   Precisao   F-medida   Classe')\n",
    "        for i in range(0,nClasses):\n",
    "            print('\\t%1.3f       %1.3f      %1.3f      %s' % (revocacao[i], precisao[i], fmedida[i],classes[i] ) )\n",
    "    \n",
    "        print('\\t------------------------------------------------')\n",
    "      \n",
    "        #imprime as médias\n",
    "        print('\\t%1.3f       %1.3f      %1.3f      Média macro' % (revocacao_macroAverage, precisao_macroAverage, fmedida_macroAverage) )\n",
    "        print('\\t%1.3f       %1.3f      %1.3f      Média micro\\n' % (revocacao_microAverage, precisao_microAverage, fmedida_microAverage) )\n",
    "\n",
    "        print('\\tAcuracia: %1.3f' %acuracia)\n",
    "      \n",
    "    \n",
    "    # guarda os resultados em uma estrutura tipo dicionario\n",
    "    resultados = {'revocacao': revocacao, 'acuracia': acuracia, 'precisao':precisao, 'fmedida':fmedida}\n",
    "    resultados.update({'revocacao_macroAverage':revocacao_macroAverage, 'precisao_macroAverage':precisao_macroAverage, 'fmedida_macroAverage':fmedida_macroAverage})\n",
    "    resultados.update({'revocacao_microAverage':revocacao_microAverage, 'precisao_microAverage':precisao_microAverage, 'fmedida_microAverage':fmedida_microAverage})\n",
    "    resultados.update({'confusionMatrix': matriz_confusao})\n",
    "\n",
    "    return resultados \n",
    "\n",
    "\n",
    "\n",
    "auxResults = relatorioDesempenho(cm, classes, imprimeRelatorio=True)\n",
    "\n",
    "print('\\n\\n\\nSe sua implementacao estiver correta, sera gerado o seguinte relatorio:\\n')\n",
    "print('\\tRevocacao   Precisao   F-medida   Classe')\n",
    "print('\\t0.724       0.743      0.733      0')\n",
    "print('\\t0.802       0.786      0.794      1')\n",
    "print('\\t-------------------------------------------------')\n",
    "print('\\t0.763       0.764      0.764      Media macro')\n",
    "print('\\t0.767       0.767      0.767      Media micro')\n",
    "print('\\n\\tAcuracia: 0.767')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva de aprendizado\n",
    "\n",
    "No teste feito acima, nós \"chutamos\" um valor para o parâmetro de regularização e já avaliamos nosso método usando os dados de teste. Porém, uma melhor avaliação do método antes de fazer o teste poderia nos ajudar a obter melhores resultados. Uma das formas de avaliar melhor o método é usando uma curva de aprendizado que pode nos ajudar, por exemplo, a detectar se o método está sofrendo de over/under fitting. Para isso, precisamos primeiro separar uma parte dos dados de treinamento em um outro subconjunto chamado validação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pTrain = 0.8\n",
    "\n",
    "# divide o conjunto de treinamento em dois outros subconjuntos\n",
    "train_index, val_index = stratified_holdOut(Y_train, pTrain)\n",
    "\n",
    "# gera as matrizes com os dados de treinamento e de validacao e os vetores \n",
    "# das classes a partir dos indices retornado pela funcao stratified_holdOut() \n",
    "Xpol_train_v, Xpol_val = Xpol_train[train_index, :], Xpol_train[val_index, :]\n",
    "Y_train_v, Y_val = Y_train[train_index], Y_train[val_index]\n",
    "\n",
    "print('Numero de dados de validação: %d' %(Xpol_val.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, você deve completar o código que gera a curva de aprendizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa as funções da regressao logística\n",
    "from logisticRegression import atributosPolinomiais, predicao, treinamento\n",
    "\n",
    "def curva_aprendizado(X, Y, Xval, Yval):\n",
    "    \"\"\"\n",
    "    Funcao usada gerar a curva de aprendizado.\n",
    "  \n",
    "    Parametros\n",
    "    ----------\n",
    "  \n",
    "    X : matriz com os dados de treinamento\n",
    "  \n",
    "    Y : vetor com as classes dos dados de treinamento\n",
    "  \n",
    "    Xval : matriz com os dados de validação\n",
    "  \n",
    "    Yval : vetor com as classes dos dados de validação\n",
    "  \n",
    "    \"\"\"\n",
    "\n",
    "    # inicializa as listas que guardarao a performance no treinamento e na validacao\n",
    "    perf_train = []\n",
    "    perf_val = []\n",
    "\n",
    "    # inicializa o parametro de regularizacao da regressao logistica\n",
    "    lambda_reg = 1\n",
    "        \n",
    "    # Configura o numero de interacaoes da regressao logistica\n",
    "    iteracoes = 500\n",
    "        \n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ###############################\n",
    "    #  Instrucoes: Complete o codigo para gerar o gráfico da curva de aprendizado.\n",
    "    #           Comece o treinamento com as primeiras 10 amostras da base de dados de \n",
    "    #           treinamento e calcule a acuracia do classificador tanto nos dados de\n",
    "    #           treinamento já apresentados, quando na base de validacao. \n",
    "    #           Depois disso, adicione mais um dado para treinamento e calcule novamente \n",
    "    #           o desempenho. Continue adicionando um dado por vez ate todos os dados de \n",
    "    #           treinamento serem usados. Nas listas perf_train e perf_val, guarde a acuracia \n",
    "    #           obtida nos dados de treinamento e na base de validacao a cada nova adicao de \n",
    "    #           dados para treinamento.\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ##################################################################################\n",
    "       \n",
    "    # Define o tamanho da figura \n",
    "    plt.figure(figsize=(20,12))\n",
    "\n",
    "    # Plota os dados\n",
    "    plt.plot(perf_train, color='blue', linestyle='-', linewidth=1.5, label='Treino') \n",
    "    plt.plot(perf_val, color='red', linestyle='-', linewidth=1.5, label='Validação')\n",
    "\n",
    "    # Define os nomes do eixo x e do eixo y\n",
    "    plt.xlabel(r'# Qtd. de dados de treinamento',fontsize='x-large') \n",
    "    plt.ylabel(r'Acuracia',fontsize='x-large') \n",
    "\n",
    "    # Define o título do gráfico\n",
    "    plt.title(r'Curva de aprendizado', fontsize='x-large')\n",
    "\n",
    "    # Acrescenta um grid no gráfico\n",
    "    plt.grid(axis='both')\n",
    "\n",
    "    # Plota a legenda\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "curva_aprendizado(Xpol_train_v, Y_train_v, Xpol_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busca em grade\n",
    "\n",
    "Para não ter que ficar tentando acertar o melhor parâmetro de regularização na sorte, é recomendado usar uma busca em grade para testar um conjunto de valores (*e.g.*, ${0,0.5,1,10,50,100})$ na predição do conjunto de validação. Posteriormente, o melhor valor encontrado pode ser usado para avaliar o método nos dados de teste.\n",
    "\n",
    "Você deverá completar a função da busca em grade para encontrar o melhor valor do parâmetro de regularização. Você vai usar o conjunto de validação que já foi gerado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(X, Y, Xval, Yval, imprimeRelatorio=True):\n",
    "    \"\"\"\n",
    "    Retorna o melhor valor para os parametros lamba da regularizacao da Regressao Logistica.\n",
    "    \n",
    "    Parametros\n",
    "    ----------\n",
    "    X : matriz com os dados de treinamento\n",
    "    \n",
    "    Y : vetor com as classes dos dados de treinamento\n",
    "    \n",
    "    Xval : matriz com os dados de validacao\n",
    "    \n",
    "    Yval : vetor com as classes dos dados de validacao\n",
    "    \n",
    "    Retorno\n",
    "    -------\n",
    "    bestReg: o melhor valor para o parametro de regularizacao\n",
    "    \n",
    "    dictPerf: variavel do tipo dicionario (dictionary). As chaves\n",
    "              desse dicionario serao os valores usados para o parametro\n",
    "              de regularizacao. O valor para cada chave sera o desempenho \n",
    "              obtido quando o valor da chave foi usado como parametro de \n",
    "              regularizacao.\n",
    "    \"\"\"\n",
    "\n",
    "    # inicializa as variáveis que deverao ser retornadas pela função\n",
    "    \n",
    "    # valores que deverao ser testados para o parametro de regularizacao \n",
    "    reg = [0.0,0.5,1.0,10.0,50.0,100.0]\n",
    "    \n",
    "    # variavel que guardara o melhor valor para o parametro de regularizacao\n",
    "    bestReg = -100 \n",
    "\n",
    "    # dicionario que guardara a acuracia obtida para cada parametro de regularizacao\n",
    "    dictPerf = {}\n",
    "    for p in reg:\n",
    "        dictPerf[p] = 0.0\n",
    "        \n",
    "    # Configura o numero de interacaoes da regressao logistica\n",
    "    iteracoes = 500\n",
    "        \n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ###############################\n",
    "    # Instrucoes: Complete esta função para retornar os melhores valores do parametro\n",
    "    #             de regularizacao da regressao Logistica. \n",
    "    #\n",
    "    #             Voce pode calcular o desempenho do classificador atraves da funcao\n",
    "    #             relatorioDesempenho() criada anteriormente. Use a acuracia para decidir\n",
    "    #             o melhor parametro.   \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ##################################################################################\n",
    "\n",
    "    return bestReg, dictPerf\n",
    "\n",
    "# chama a função que faz a busca em grade\n",
    "bestRegularization, dictPerf = gridSearch(Xpol_train_v, Y_train_v, Xpol_val, Y_val)\n",
    "\n",
    "print('\\nMelhor parâmetro de regularizacao encontrado: %1.3f' %(bestRegularization))\n",
    "\n",
    "print('\\nAcuracia obtida para cada valor de regularizacao testado:')\n",
    "print('\\treg: acc')\n",
    "for key in dictPerf:\n",
    "    print('\\t%1.2f: %1.2f' %(key, dictPerf[key]))\n",
    "\n",
    "print('\\n\\n\\nO melhor parametro de regularizacao deve ser igual a 0.000')\n",
    "\n",
    "print('\\nOs desempenhos esperados eram: ')\n",
    "print('\\treg: acc')\n",
    "print('\\t0.00: 0.97\\n\\t0.50: 0.88\\n\\t1.00: 0.88\\n\\t10.00: 0.74\\n\\t50.00: 0.57\\n\\t100.00: 0.56')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que encontramos o melhor parâmetro de regularização, vamos treinar o método com todos os dados de treinamento e testá-lo com os dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executa o treinamento com o melhor parâmetro de regularização encontrado\n",
    "theta = treinamento(Xpol_train, Y_train, bestRegularization, iteracoes)\n",
    "\n",
    "# classifica os dados de teste\n",
    "Y_pred = predicao(Xpol_test, theta)\n",
    "\n",
    "# gera a matriz de confusão\n",
    "cm = get_confusionMatrix(Y_test, Y_pred, classes)\n",
    "\n",
    "# Gera o relatório de desempenho\n",
    "auxResults = relatorioDesempenho(cm, classes, imprimeRelatorio=True)\n",
    "\n",
    "print('\\n\\n\\nSe sua implementacao estiver correta, sera gerado o seguinte relatorio de desempenho:\\n')\n",
    "print('\\tRevocacao   Precisao   F-medida   Classe')\n",
    "print('\\t0.934       0.899      0.916      0')\n",
    "print('\\t0.917       0.946      0.931      1')\n",
    "print('\\t-------------------------------------------------')\n",
    "print('\\t0.925       0.922      0.924      Media macro')\n",
    "print('\\t0.924       0.924      0.924      Media micro')\n",
    "print('\\n\\tAcuracia: 0.924')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: K-fold \n",
    "\n",
    "A validação cruzada $k$-fold é considerada mais robusta que a validação por *holdout*, pois ela garante que o algoritmo será avaliado com todas as amostras da base de dados.\n",
    "\n",
    "Para prosseguir com os experimentos com essa nova validação, vamos carregar os dados novamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a biblioteca matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np #importa a biblioteca usada para trabalhar com vetores de matrizes\n",
    "import pandas as pd #importa a biblioteca usada para trabalhar com dataframes (dados em formato de tabela) e análise de dados\n",
    "\n",
    "# Importa o arquivo e guarda em um dataframe do Pandas\n",
    "df_dataset3 = pd.read_csv( os.path.join(FILES_DIRECTORY, 'data.csv'), sep=',', index_col=None)\n",
    "\n",
    "# Pega os valores das n-1 primeiras colunas e guarda em uma matrix X\n",
    "X3 = df_dataset.iloc[:, 0:-1].values \n",
    "\n",
    "# Pega os valores da ultima coluna e guarda em um vetor Y\n",
    "Y3 = df_dataset.iloc[:, -1].values \n",
    "\n",
    "# Imprime as 5 primeiras linhas da matriz X\n",
    "display('X:', X3[0:5,:])\n",
    "\n",
    "# Imprime os 5 primeiros valores de Y\n",
    "print('Y:', Y3[0:5])\n",
    "\n",
    "# obtem e imprimi as classes do problema\n",
    "classes = np.unique(Y3)\n",
    "print('\\nClasses: ', classes)    \n",
    "\n",
    "#chamando a função que plota os dados   \n",
    "visualizarDados(X,Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É importante que as partições sejam geradas de forma aleatória. Portanto, no script abaixo, antes de chamarmos a função que gera os conjuntos de treinamento e teste, iremos embaralhar os dados. Para que toda a execução gere o mesmo resultado, vamos usar uma semente para a função de geração de números aleatórios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semente usada na randomizacao dos dados.\n",
    "randomSeed = 10 \n",
    "\n",
    "# gera os indices aleatorios que irao definir a ordem dos dados\n",
    "idx_perm = np.random.RandomState(randomSeed).permutation(range(len(Y3)))\n",
    "\n",
    "# ordena os dados de acordo com os indices gerados aleatoriamente\n",
    "X4, Y4 = X3[idx_perm, :], Y3[idx_perm]\n",
    "\n",
    "print('Dados embaralhados com sucesso!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, você deverá implementar a validação cruzada *k*-fold estratificada. Na versão estratificada, cada partição deve conter aproximadamente a mesma distribuição original de dados de cada classe. Na sua implementação, você deve dividir os dados em $k$ folds. Para cada rodada $k$, os dados da $k$-ésima partição devem compor os dados de teste, enquanto os dados das outras partições devem compor os dados de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_kfolds(target, k, classes):\n",
    "    \"\"\"\n",
    "    Retorna os indices dos dados de treinamento e teste para cada uma das k rodadas \n",
    "    \n",
    "    Parametros\n",
    "    ----------   \n",
    "    target: vetor com as classes dos dados\n",
    "    \n",
    "    k: quantidade de folds \n",
    "    \n",
    "    Retorno\n",
    "    -------\n",
    "    folds_final: os indices dos dados de treinamento e teste para cada uma das k rodadas \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Inicializa a variavel que precisa ser retornada. \n",
    "    # Cada elemento do vetor folds_final deve ser outro vetor de duas posicoes: a primeira\n",
    "    #    posicao deve conter um vetor com os indices de treinamento relativos ao i-esimo fold;\n",
    "    #    a segunda posicao deve conter um vetor com os indices de teste relativos ao i-esimo fold.\n",
    "    folds_final = np.zeros( k,dtype='object')\n",
    "\n",
    "    # inicializa o vetor onde o k-esimo elemento guarda os indices dos dados de treinamento \n",
    "    # relativos ao k-esimo fold \n",
    "    train_index = np.zeros( k,dtype='object')\n",
    "    \n",
    "    # inicializa o vetor onde o k-esimo elemento guarda os indices dos dados de teste \n",
    "    # relativos ao k-esimo fold \n",
    "    test_index = np.zeros( k,dtype='object')\n",
    "    \n",
    "    # inicializa cada posicao do vetor folds_final que devera ser retornado pela funcao\n",
    "    for i in range( len(folds_final) ):\n",
    "        \n",
    "        train_index[i] = [] # indices dos dados de treinamento relativos ao fold i\n",
    "        test_index[i] = [] # indices dos dados de teste relativos ao fold i\n",
    "        \n",
    "        # inicializa o i-esimo elemento do vetor que devera ser retornado\n",
    "        folds_final[i] = np.array( [train_index[i],test_index[i]], dtype='object' ) \n",
    "      \n",
    "    \n",
    "\n",
    "    ########################## COMPLETE O CÓDIGO AQUI  ###############################\n",
    "    #  Instrucoes: Complete o codigo para retornar os indices dos dados de  \n",
    "    #              treinamento e dos dados de teste para cada rodada do k-folds.\n",
    "    #              \n",
    "    #              Obs: - os conjuntos de treinamento e teste devem ser criados\n",
    "    #                     de maneira estratificada, ou seja, deve ser mantida a \n",
    "    #                     a proporcao original dos dados de cada classe em cada \n",
    "    #                     conjunto.\n",
    "    \n",
    "    #                   - Para cada rodada k, os dados da k-esima particao devem compor \n",
    "    #                     os dados de teste, enquanto os dados das outras particoes devem \n",
    "    #                     compor os dados de treinamento.\n",
    "    \n",
    "    #                   - voce devera retornar a variavel folds_final: essa variavel e um \n",
    "    #                     vetor de k posicoes. Cada posicao k do vetor folds_final deve conter \n",
    "    #                     outro vetor de duas posicoes: a primeira posicao deve conter um vetor \n",
    "    #                     com os indices de treinamento relativos ao k-esimo fold; a segunda posicao \n",
    "    #                     deve conter um vetor com os indices de teste relativos ao k-esimo fold. \n",
    "    \n",
    "    #                   - IMPORTANTE: por se tratar de vetores cujos elementos são vetores de\n",
    "    #                     tamanhos diferentes, ao declarar estes vetores internos, é necessário fornecer\n",
    "    #                     dtype='object', da mesma maneira que feito nesta mesma função, na declaração acima.\n",
    "    \n",
    "    #                   -  dentro de uma determinada particao, mantenha a ordem dos dados igual\n",
    "    #                      a ordem original do vetor target. Exemplo: se as amostras com os índices 1, 3 e 6 foram \n",
    "    #                      escolhidas para fazerem parte da segunda particao, garanta que na segunda particao \n",
    "    #                      elas permanecam na mesma ordem: a amostra de índice 1 fique antes da amostra de índice 3\n",
    "    #                      e esta fique antes da amostra de indice 6. \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ##################################################################################\n",
    "    \n",
    "    return folds_final\n",
    "\n",
    "# separa os dados em k folds\n",
    "nFolds = 5\n",
    "folds = stratified_kfolds(Y4, nFolds, classes)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo são exibidas algumas informações sobre as partições retornadas pela função ``stratified_kfolds()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "for train_index, test_index in folds:\n",
    "\n",
    "    print('\\n-----------\\n%d-fold: \\n-----------\\n' % (k) )\n",
    "\n",
    "    # se train_index ou test_index forem vazios, interrompe o laco de repeticao\n",
    "    if len(train_index)==0 or len(test_index)==0: \n",
    "        print('\\tErro: o vetor com os indices de treinamento ou o vetor com os indices de teste esta vazio')      \n",
    "        break\n",
    "\n",
    "    X_train, X_test = X4[train_index, :], X4[test_index, :]\n",
    "    Y_train, Y_test = Y4[train_index], Y4[test_index]\n",
    "\n",
    "    print('\\tQtd. dados de treinamento: %d (%1.2f%%)' %(X_train.shape[0], (X_train.shape[0]/X.shape[0])*100) )\n",
    "    print('\\tQtd. de dados de teste: %d (%1.2f%%)' %(X_test.shape[0], (X_test.shape[0]/X.shape[0])*100) )\n",
    "\n",
    "    # imprime a porcentagem de dados de treinamento de cada classe\n",
    "    print(\"\\n\\tQtd. de dados de cada classe (treinamento)\")\n",
    "    cTrain, counts_cTrain = np.unique(np.sort(Y_train), return_counts=True)\n",
    "    for i in range( len(cTrain) ):\n",
    "        print('\\t\\tClasse %s: %d (%1.2f%%)' %( cTrain[i],counts_cTrain[i],(counts_cTrain[i]/len(Y_train))*100 ) )\n",
    "\n",
    "    # imprime a porcetagem de dados de teste de cada classe\n",
    "    print(\"\\n\\tQtd. de dados de cada classe (teste)\")\n",
    "    cTest, counts_cTest = np.unique(np.sort(Y_test), return_counts=True)\n",
    "    for i in range( len(cTrain) ):\n",
    "        print('\\t\\tClasse %s: %d (%1.2f%%)' %( cTest[i],counts_cTest[i],(counts_cTest[i]/len(Y_test))*100 ) )\n",
    "\n",
    "    k = k + 1\n",
    "\n",
    "\n",
    "print('\\n\\n\\n'+\"-\"*80+'\\nSe sua implementacao estiver corretas, cada uma das 5 rodadas deve conter:')\n",
    "print('\\t- 304 dados de treinamento da classe 0 (44.19%)')\n",
    "print('\\t- 384 dados de treinamento da classe 1 (55.81%)')\n",
    "\n",
    "print('\\nSe sua implementacao estiver correta, cada fold deve conter:')\n",
    "print('\\t- 76 dados de teste da classe 0 (44.19%)')\n",
    "print('\\t- 96 dados de teste da classe 1 (55.81%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que separamos os dados em partições, vamos executar o algoritmo em cada *fold* gerado e calcular o resultado. Em cada *fold*, deve ser usada a busca em grade para encontrar o melhor parâmetro de regularização. Além disso, como os dados não são linearmente separáveis, iremos gerar atributos polinomiais antes de executar o treinamento e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa as funções da regressao logística\n",
    "from logisticRegression import atributosPolinomiais, predicao, treinamento\n",
    "    \n",
    "# inicializa o parametro que defini o numero de iteracoes da regressão logística\n",
    "iteracoes = 1000\n",
    "\n",
    "k = 1\n",
    "resultados=[] # cria uma lista vazia para guardar os resultados obtidos em cada fold\n",
    "\n",
    "for train_index, test_index in folds:\n",
    "    print('\\n-----------\\n%d-fold: \\n-----------\\n' % (k) )\n",
    "\n",
    "    # se train_index ou test_index forem vazios, interrompe o laco de repeticao\n",
    "    if len(train_index)==0 or len(test_index)==0: \n",
    "        print('\\tErro: o vetor com os indices de treinamento ou o vetor com os indices de teste esta vazio')      \n",
    "        break\n",
    "\n",
    "    totalFold = len(train_index)+len(test_index)\n",
    "\n",
    "    X_train, X_test = X4[train_index, :], X4[test_index, :]\n",
    "    Y_train, Y_test = Y4[train_index], Y4[test_index]\n",
    "\n",
    "    # adiciona novas colunas que correspondem a atributos polinomiais\n",
    "    Xpol_train = atributosPolinomiais(X_train[:,0],X_train[:,1]) \n",
    "    Xpol_test = atributosPolinomiais(X_test[:,0],X_test[:,1]) \n",
    "\n",
    "    # separa os dados de treinamento em treinamento e validacao\n",
    "    pTrain = 0.8\n",
    "    train_index_v, val_index = stratified_holdOut(Y_train, pTrain)\n",
    "\n",
    "    Xpol_train_v, Xpol_val = Xpol_train[train_index_v, :], Xpol_train[val_index, :]\n",
    "    Y_train_v, Y_val = Y_train[train_index_v], Y_train[val_index]\n",
    "\n",
    "    # chama a função que faz a busca em grade\n",
    "    bestRegularization, dictPerf = gridSearch(Xpol_train_v, Y_train_v, Xpol_val, Y_val)\n",
    "\n",
    "    # executa o treinamento com o melhor parâmetro de regularização encontrado\n",
    "    theta = treinamento(Xpol_train, Y_train, bestRegularization, iteracoes)\n",
    "\n",
    "    # classifica os dados de teste\n",
    "    Y_pred = predicao(Xpol_test, theta)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = get_confusionMatrix(Y_test, Y_pred, classes)\n",
    "\n",
    "    # Gera o relatório de desempenho\n",
    "    print('\\n\\n\\n\\t'+\"=\"*50+'\\n\\tMelhor parametro de regularizacao: %1.6f' %bestRegularization)\n",
    "    print('\\n\\tResultado no fold atual usando o melhor parametro encontrado:')\n",
    "    auxResults = relatorioDesempenho(cm, classes, imprimeRelatorio=True)\n",
    "\n",
    "    # adiciona os resultados do fold atual na lista de resultados\n",
    "    resultados.append( auxResults ) \n",
    "\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, precisamos calcular o desempenho final do algoritmo. Para isso, basta calcular a média dos resultados obtidos em cada fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediaFolds( resultados, classes ):\n",
    "\n",
    "    nClasses = len(classes)\n",
    "\n",
    "    acuracia = np.zeros( len(resultados) )\n",
    "\n",
    "    revocacao = np.zeros( [len(resultados),len(classes)] )\n",
    "    precisao = np.zeros( [len(resultados),len(classes)] )\n",
    "    fmedida = np.zeros( [len(resultados),len(classes)] )\n",
    "\n",
    "    revocacao_macroAverage = np.zeros( len(resultados) )\n",
    "    precisao_macroAverage = np.zeros( len(resultados) )\n",
    "    fmedida_macroAverage = np.zeros( len(resultados) )\n",
    "\n",
    "    revocacao_microAverage = np.zeros( len(resultados) )\n",
    "    precisao_microAverage = np.zeros( len(resultados) )\n",
    "    fmedida_microAverage = np.zeros( len(resultados) )\n",
    "\n",
    "\n",
    "    for i in range(len(resultados)):\n",
    "        acuracia[i] = resultados[i]['acuracia']\n",
    "\n",
    "        revocacao[i,:] = resultados[i]['revocacao']\n",
    "        precisao[i,:] = resultados[i]['precisao']\n",
    "        fmedida[i,:] = resultados[i]['fmedida']\n",
    "\n",
    "        revocacao_macroAverage[i] = resultados[i]['revocacao_macroAverage']\n",
    "        precisao_macroAverage[i] = resultados[i]['precisao_macroAverage']\n",
    "        fmedida_macroAverage[i] = resultados[i]['fmedida_macroAverage']\n",
    "\n",
    "        revocacao_microAverage[i] = resultados[i]['revocacao_microAverage']\n",
    "        precisao_microAverage[i] = resultados[i]['precisao_microAverage']\n",
    "        fmedida_microAverage[i] = resultados[i]['fmedida_microAverage']\n",
    "\n",
    "    # imprimindo os resultados para cada classe\n",
    "    print('\\n\\tRevocacao   Precisao   F-medida   Classe')\n",
    "    for i in range(0,nClasses):\n",
    "        print('\\t%1.3f       %1.3f      %1.3f      %s' % (np.mean(revocacao[:,i]), np.mean(precisao[:,i]), np.mean(fmedida[:,i]), classes[i] ) )\n",
    "\n",
    "    print('\\t---------------------------------------------------------------------')\n",
    "\n",
    "    #imprime as medias\n",
    "    print('\\t%1.3f       %1.3f      %1.3f      Média macro' % (np.mean(revocacao_macroAverage), np.mean(precisao_macroAverage), np.mean(fmedida_macroAverage)) )\n",
    "    print('\\t%1.3f       %1.3f      %1.3f      Média micro\\n' % (np.mean(revocacao_microAverage), np.mean(precisao_microAverage), np.mean(fmedida_microAverage)) )\n",
    "\n",
    "    print('\\tAcuracia: %1.3f' %np.mean(acuracia))\n",
    "\n",
    "\n",
    "# imprime a media dos folds\n",
    "print('\\nResultado final da classificação:')\n",
    "mediaFolds( resultados, classes )\n",
    "\n",
    "print('\\n\\n\\nSe sua implementacao estiver correta, sera gerado o seguinte relatorio:\\n')\n",
    "print('\\tRevocacao   Precisao   F-medida   Classe')\n",
    "print('\\t0.913       0.894      0.904      0')\n",
    "print('\\t0.915       0.930      0.922      1')\n",
    "print('\\t-------------------------------------------------')\n",
    "print('\\t0.914       0.912      0.913      Media macro')\n",
    "print('\\t0.914       0.914      0.914      Media micro')\n",
    "print('\\n\\tAcuracia: 0.914')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
